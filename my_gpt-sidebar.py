from openai import OpenAI, RateLimitError
import streamlit as st
from datetime import datetime

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ë‚˜ë§Œì˜ ChatGPT", layout="wide")

# ğŸ’¾ API í‚¤ ë¡œë“œ
client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

# ğŸ§  ëª¨ë¸ ì„¤ì •
if "openai_model" not in st.session_state:
    st.session_state["openai_model"] = "gpt-4o"

# ğŸ’¬ ëŒ€í™” ì €ì¥ì†Œ ì´ˆê¸°í™”
if "conversations" not in st.session_state:
    st.session_state["conversations"] = {}

# â–¶ï¸ í˜„ì¬ ëŒ€í™” ID ì„¤ì •
if "current_conversation" not in st.session_state:
    default_name = datetime.now().strftime("ëŒ€í™” %Y-%m-%d %H:%M:%S")
    st.session_state["current_conversation"] = default_name
    st.session_state["conversations"][default_name] = []

# ğŸ§­ ì‚¬ì´ë“œë°”: ëŒ€í™” ì„ íƒ ë° ìƒˆë¡œ ë§Œë“¤ê¸°
with st.sidebar:
    st.header("ğŸ—‚ï¸ ëŒ€í™” ì´ë ¥")
    selected = st.radio(
        "ê¸°ì¡´ ëŒ€í™” ì„ íƒ",
        options=list(st.session_state["conversations"].keys()),
        index=list(st.session_state["conversations"].keys()).index(st.session_state["current_conversation"]),
    )
    if selected != st.session_state["current_conversation"]:
        st.session_state["current_conversation"] = selected

    if st.button("â• ìƒˆ ëŒ€í™” ì‹œì‘"):
        new_name = datetime.now().strftime("ëŒ€í™” %Y-%m-%d %H:%M:%S")
        st.session_state["conversations"][new_name] = []
        st.session_state["current_conversation"] = new_name

# ğŸ‘‰ ì±„íŒ… ì˜ì—­: ê°€ìš´ë°ë§Œ ì‚¬ìš©
left_col, center_col, right_col = st.columns([1, 2, 1])

with center_col:
    # âœ… ì…ë ¥ì°½ CSS ìŠ¤íƒ€ì¼ ì¡°ì •
    st.markdown("""
        <style>
        textarea[data-testid="stChatInput"] {
            width: 400px !important;
            height: 200px !important;  /* âœ… ì´ ì¤„ ì¶”ê°€ */
            margin: auto !important;
        }
        </style>
    """, unsafe_allow_html=True)

    # ì—¬ë°±
    st.markdown("<div style='height: 800px;'></div>", unsafe_allow_html=True)

    st.title("ë‚˜ë§Œì˜ ChatGPT")

    # í˜„ì¬ ëŒ€í™” ë¶ˆëŸ¬ì˜¤ê¸°
    messages = st.session_state["conversations"][st.session_state["current_conversation"]]

    # ğŸ’¬ ì´ì „ ë©”ì‹œì§€ ì¶œë ¥
    for message in messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # ğŸ“¥ ì‚¬ìš©ì ì…ë ¥ ë° ì²˜ë¦¬
    if prompt := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”."):
        messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # ğŸ¤– ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µ
        with st.chat_message("assistant"):
            try:
                stream = client.chat.completions.create(
                    model=st.session_state["openai_model"],
                    messages=[{"role": m["role"], "content": m["content"]} for m in messages],
                    stream=True,
                )

                full_response = ""
                placeholder = st.empty()

                for chunk in stream:
                    content = getattr(chunk.choices[0].delta, "content", None)
                    if content:
                        full_response += content
                        placeholder.markdown(full_response)

                messages.append({"role": "assistant", "content": full_response})

            except RateLimitError:
                st.error("âš ï¸ ìš”ì²­ì´ ë„ˆë¬´ ë§ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")
            except Exception as e:
                st.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
