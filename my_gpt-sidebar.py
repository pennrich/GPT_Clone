from openai import OpenAI, RateLimitError
import streamlit as st
from datetime import datetime

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ë‚˜ë§Œì˜ ChatGPT", layout="wide")

# ğŸ’¾ API í‚¤ ë¡œë“œ
client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

# ğŸ§  ëª¨ë¸ ì„¤ì •
if "openai_model" not in st.session_state:
    st.session_state["openai_model"] = "gpt-4o"

# ğŸ’¬ ëŒ€í™” ì €ì¥ì†Œ ì´ˆê¸°í™”
if "conversations" not in st.session_state:
    st.session_state["conversations"] = {}

# â–¶ï¸ í˜„ì¬ ëŒ€í™” ID ì„¤ì •
if "current_conversation" not in st.session_state:
    default_name = datetime.now().strftime("ëŒ€í™” %Y-%m-%d %H:%M:%S")
    st.session_state["current_conversation"] = default_name
    st.session_state["conversations"][default_name] = []

# ğŸ§­ ì‚¬ì´ë“œë°”: ëŒ€í™” ì„ íƒ ë° ìƒˆë¡œ ë§Œë“¤ê¸°
with st.sidebar:
    st.header("ğŸ—‚ï¸ ëŒ€í™” ì´ë ¥")
    selected = st.radio(
        "ê¸°ì¡´ ëŒ€í™” ì„ íƒ",
        options=list(st.session_state["conversations"].keys()),
        index=list(st.session_state["conversations"].keys()).index(st.session_state["current_conversation"]),
    )
    if selected != st.session_state["current_conversation"]:
        st.session_state["current_conversation"] = selected

    if st.button("â• ìƒˆ ëŒ€í™” ì‹œì‘"):
        new_name = datetime.now().strftime("ëŒ€í™” %Y-%m-%d %H:%M:%S")
        st.session_state["conversations"][new_name] = []
        st.session_state["current_conversation"] = new_name

# ğŸ‘‰ ì±„íŒ… ì˜ì—­: ê°€ìš´ë°ë§Œ ì‚¬ìš©
left_col, center_col, right_col = st.columns([1, 2, 1])

with center_col:
    # í˜„ì¬ ëŒ€í™” ë¶ˆëŸ¬ì˜¤ê¸°
    messages = st.session_state["conversations"][st.session_state["current_conversation"]]

    # ğŸ”§ CSSë¡œ ìˆ˜ì§ ì •ë ¬
    st.markdown("""
        <style>
            .full-height {
                display: flex;
                flex-direction: column;
                justify-content: space-between;
                height: 90vh;
                padding: 5vh 0;
            }
            .centered-title h1 {
                text-align: center;
            }
        </style>
    """, unsafe_allow_html=True)

    # ğŸ”² ì „ì²´ í™”ë©´ì„ ìˆ˜ì§ ë¶„í• 
    with st.container():
        st.markdown('<div class="full-height">', unsafe_allow_html=True)

        # ì œëª© (ìœ„ìª½)
        st.markdown('<div class="centered-title"><h1>ChatGPT-like clone</h1></div>', unsafe_allow_html=True)

        # ğŸ’¬ ì´ì „ ë©”ì‹œì§€ ì¶œë ¥
        for message in messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

        # í…ìŠ¤íŠ¸ë°•ìŠ¤ (ì•„ë˜ìª½)
        if prompt := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”."):
            messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)

            # ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µ ì²˜ë¦¬
            with st.chat_message("assistant"):
                try:
                    stream = client.chat.completions.create(
                        model=st.session_state["openai_model"],
                        messages=[{"role": m["role"], "content": m["content"]} for m in messages],
                        stream=True,
                    )

                    full_response = ""
                    placeholder = st.empty()

                    for chunk in stream:
                        content = getattr(chunk.choices[0].delta, "content", None)
                        if content:
                            full_response += content
                            placeholder.markdown(full_response)

                    messages.append({"role": "assistant", "content": full_response})

                except RateLimitError:
                    st.error("âš ï¸ ìš”ì²­ì´ ë„ˆë¬´ ë§ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")
                except Exception as e:
                    st.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")

        st.markdown('</div>', unsafe_allow_html=True)

    st.title("ë‚˜ë§Œì˜ ChatGPT")
    
    # ğŸ’¬ ì´ì „ ë©”ì‹œì§€ ì¶œë ¥
    for message in messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # ğŸ“¥ ì‚¬ìš©ì ì…ë ¥
    if prompt := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”."):
        messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # ğŸ¤– ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µ
        with st.chat_message("assistant"):
            try:
                stream = client.chat.completions.create(
                    model=st.session_state["openai_model"],
                    messages=[{"role": m["role"], "content": m["content"]} for m in messages],
                    stream=True,
                )

                full_response = ""
                placeholder = st.empty()

                for chunk in stream:
                    content = getattr(chunk.choices[0].delta, "content", None)
                    if content:
                        full_response += content
                        placeholder.markdown(full_response)

                messages.append({"role": "assistant", "content": full_response})

            except RateLimitError:
                st.error("âš ï¸ ìš”ì²­ì´ ë„ˆë¬´ ë§ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")
            except Exception as e:
                st.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")

